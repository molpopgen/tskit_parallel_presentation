{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e94797",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experimenting with parallel computation using tskit\n",
    "\n",
    "* Kevin Thornton\n",
    "* 7 December, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce8f0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "* Improving tree access\n",
    "* One possible path to simplification using threads.\n",
    "  * This is the simplest/most obvious method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544b4d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Technicalities\n",
    "\n",
    "* I am only talking about `tskit-c`\n",
    "* I will show pseudocode in Python\n",
    "* I did everything in rust, using `tskit-rust`.\n",
    "* Yes, that's confusing..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5bf567",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Background\n",
    "\n",
    "* Multithreaded programming is hard.\n",
    "* tskit **should probably never bother with it directly**.\n",
    "  * There are lots of reasons for it.\n",
    "* tskit should:\n",
    "  * think about how to alleviate barriers to parallelism\n",
    "  * Document what safe access to data structures looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa6cd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tree access\n",
    "\n",
    "* `int tsk_tree_seek(tsk_tree_t *self, double position, tsk_flags_t options);`\n",
    "* Does a linear time search from front/back based on if position < or > L/2.\n",
    "* Work flows wanting to start from arbitrary trees become quadratic time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af3d61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Indexing trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e718f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class TreeIndex:\n",
    "    insertion: List[int]\n",
    "    removal: List[int]\n",
    "    left: List[float]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7cdda",
   "metadata": {},
   "source": [
    "* Each list is `num_trees` long.\n",
    "* The integers are the tree index for an edge insertion or removal.\n",
    "* The float is the left coordinate of a tree.\n",
    "* The lists are populated by the \"usual\" loop over edges, processing removals and insertions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02a864",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The \"usual\" loop (snippet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c199339",
   "metadata": {},
   "source": [
    " ```rust\n",
    "     while j < num_edges || tree_left < sequence_length {\n",
    "        insertion.push(j);\n",
    "        removal.push(k);\n",
    "        left.push(OrderedFloat(tree_left));\n",
    "        while k < num_edges && edge_right[edge_removal_order[k] as usize] == tree_left {\n",
    "            k += 1;\n",
    "        }\n",
    "        while j < num_edges && edge_left[edge_insertion_order[j] as usize] == tree_left {\n",
    "            j += 1;\n",
    "        }\n",
    "        tree_right = sequence_length;\n",
    "        if j < num_edges {\n",
    "            tree_right = if tree_right < edge_left[edge_insertion_order[j] as usize] {\n",
    "                tree_right\n",
    "            } else {\n",
    "                edge_left[edge_insertion_order[j] as usize]\n",
    "            };\n",
    "        }\n",
    "        if k < num_edges {\n",
    "            tree_right = if tree_right < edge_right[edge_removal_order[k] as usize] {\n",
    "                tree_right\n",
    "            } else {\n",
    "                edge_right[edge_removal_order[k] as usize]\n",
    "            };\n",
    "        }\n",
    "        tree_left = tree_right;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2d069",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Procedure\n",
    "\n",
    "1. Build the indexes\n",
    "2. Do some tedious setup on the back end:\n",
    "   * We need `tsk_tree_insert_edge`, which is not pubic.\n",
    "   * I made a nasty hack of that logic into rust code.\n",
    "   * The hack is fragile: a later update of the tskit-c\n",
    "     back end in tskit-rust breaks my spaghetti code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bfa4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Benchmark\n",
    "\n",
    "* AMD 5900x in ECO mode.\n",
    "\n",
    "Get the average of total branch length over trees:\n",
    "\n",
    "```sh\n",
    "./target/release/parallel_tree_experiments --treefile treefile.trees -w 5000 -n 12\n",
    "```\n",
    "\n",
    "Results:\n",
    "```\n",
    "File treefile.trees contains SizeType(456990) trees and SizeType(100000) samples\n",
    "avg. total time = 483811.7842241256\n",
    "duration using 12 threads = 93.571752561s\n",
    "avg. total time from single-threaded pass = 483811.78422411595\n",
    "duration from single-treaded method = 723.812803844s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dea875",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# API proposal\n",
    "\n",
    "```c\n",
    "// forward declaration only!\n",
    "struct tsk_tree_index_thing;\n",
    "\n",
    "int tsk_index_tables(const tsk_table_collection_t *, tsk_tree_index_thing *);\n",
    "int tsk_advance_to_tree_by_index(...);\n",
    "int tsk_advance_to_tree_by_position(...);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3dad5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What could we do?\n",
    "\n",
    "* Much faster analyses tree-based of large tree sequences\n",
    "\n",
    "## Caveats\n",
    "\n",
    "* This stuff is playing very dangerous games with memory:\n",
    "  * trees have pointers to tree sequences which have pointers to table collections that they may or may not own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d606372",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Is parallel tree access the way to improve performance?\n",
    "\n",
    "Probably not:\n",
    "\n",
    "* Using edge differences is probably 10x faster than the threaded method in the previous slide.\n",
    "* See [this comment](https://github.com/tskit-dev/tskit/discussions/2623#discussioncomment-4159563).\n",
    "* What we *really* want is to be able to start an edge differences iterator from an arbitrary tree/position.\n",
    "  * Then we can consider parallel statistics\n",
    "  * Unclear if this will pay off -- the work load of incremental updates may not justify threads except in extreme cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be64199",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel tree sequence recording\n",
    "\n",
    "* Imagine we split our sim into `k` table collections.\n",
    "* Each is `w = 1/k` of the genome.\n",
    "* For a new edge (or site), is is trivial to figure out which table collection(s) it should be added to.* New births (nodes) get recorded into all `k` table collections.\n",
    "* We simplify the vector of table collections using a thread pool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b2e20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why can't this \"just work\"?\n",
    "\n",
    "* Node remapping prevents this scheme from working right out of the box.\n",
    "* For each of the `k` table collections, the same input node may/will get mapped to **different** output nodes.\n",
    "* You therefore lose the node identity across your set of tree sequences.\n",
    "  * This is really bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41640470",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# One solution\n",
    "\n",
    "* Prevent nodes from being remapped!\n",
    "* [2619](https://github.com/tskit-dev/tskit/pull/2619) implements this, but is not merged yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe06683c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why is this a solution?\n",
    "\n",
    "* Output id == input id, preserving identity left-to-right.  Yay!\n",
    "* But we gets lots of extinct nodes sticking around. Boo!\n",
    "\n",
    "For a given table collection, it is easy to figure out which nodes are actually still valid:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d1819",
   "metadata": {},
   "source": [
    "```python\n",
    "# pseudocode\n",
    "used = [0]*len(tables.num_nodes)\n",
    "for e in tables.edges:\n",
    "    used[e.parent] = 1\n",
    "    used[e.child] = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be296c6f",
   "metadata": {},
   "source": [
    "Vector-wise summing the `used` arrays over all table collections tells us about \"globally\" extinct nodes.\n",
    "Any indexes where the value is 0 has been globally simplified out. We can find these indexes very quickly and put them in a queue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3ff6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why does this matter?\n",
    "\n",
    "* We know the index of all nodes that are simplifed out of all `k` table collections.\n",
    "* So we can figure out in `O(1)` time what they are (b/c we've aggregated that info)...\n",
    "* ...so we can over-write existing node data w/info for new births.\n",
    "\n",
    "(Remember -- this is all in the C API where we can touch these raw arrays.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6640c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Get to the point already...\n",
    "\n",
    "We can now \"easily\":\n",
    "\n",
    "* Record edges to the right subset of table collections.\n",
    "* Likewise new sites.\n",
    "* We no longer lose node identity once `2619` is merged.\n",
    "\n",
    "Therefore:\n",
    "\n",
    "* Simplifying the `k` table collections using threads \"just works\":\n",
    "  * the `k` table collections are fully independent data structures.\n",
    "  * We need a single-thread job to aggregate the globally extinct node info.\n",
    "  * Need a final \"collect & simplify\" step to get everything into one tree sequence for putput."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc60c70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Is it really that easy?\n",
    "\n",
    "It is a \"one liner\" in rust (using [rayon](https://docs.rs/rayon/1.6.0/rayon/)):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86468fe",
   "metadata": {},
   "source": [
    "```rust\n",
    "    // vector of table collections\n",
    "    tables\n",
    "        .par_iter_mut()\n",
    "        .map(|tc| {\n",
    "            // Records the new nodes to each tree seq and then sorts & simplifies\n",
    "            simplify_details(flags, alive, &samples, tc, new_data)\n",
    "        })\n",
    "        // Nothing gets returned\n",
    "        .collect::<()>();\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd8d21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Running simulations\n",
    "\n",
    "* Constant size WF model.\n",
    "* Number of crossovers per birth is Poisson.\n",
    "* Nothing interesting happening -- just record, simplify, repeat.\n",
    "\n",
    "## Details\n",
    "\n",
    "* Simplify every 100 generations\n",
    "* Release builds (important!)\n",
    "* `KEEP_INPUT_ROOTS` is on, just \"for fun\".\n",
    "* AMD 5900x w/64GB DDR4 3600 memory.\n",
    "* AMD 5950x w/128GB DDR4 3600 memory.\n",
    "* Entire edge table sorted each time. (Lazy...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae562f69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Performance: 1 thread vs 6\n",
    "\n",
    "![](benchmark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9447b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Performance: relative change due to 6 threads\n",
    "\n",
    "![](benchmark_relative.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f8cb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Performance: vary mean no. crossovers (inset), no. threads\n",
    "\n",
    "The hi-crossover simulation for N=5e5 crashed on my machine with 128GB.\n",
    "This machine has 16 physical cores, 32 threads.\n",
    "\n",
    "![](benchmark_threads.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb0e27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thoughts\n",
    "\n",
    "* 4x speedup is pretty good!\n",
    "* As always, naive use of threads **slows your work down**\n",
    "  * numpy installed through conda is a prime example of this...\n",
    "* Threading efficiency maximizes at ~75%. (Not an unusual number for start/stop work flows.)\n",
    "* The sims with the greatest payoff took at least 30GB of RAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d5324",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GPU?\n",
    "\n",
    "Completely ignoring the software architecture issues:\n",
    "\n",
    "* The most payoff was for sims taking loads of memory.\n",
    "* Gaming GPU with 24GB of VRAM cost at least $1500 US.\n",
    "* Data center GPU cost about 10X more.\n",
    "  * These don't burn a hole in our desk..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
